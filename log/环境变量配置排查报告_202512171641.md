# 真心话/大冒险项目 - 环境变量配置排查报告

**排查时间**: 2025-12-17 16:41  
**排查人**: Claude AI Assistant  
**排查目标**: 检查代码中应该迁移到环境文件的配置信息

---

## 一、排查结果总览

### 当前状态

| 类别 | 当前处理方式 | 建议 |
|------|------------|------|
| **API Keys** | ✅ 已使用环境变量 | 保持现状 |
| **API Base URLs** | ⚠️ 硬编码在代码中 | 建议迁移到环境变量 |
| **LLM Model Names** | ⚠️ 硬编码在代码中 | 建议迁移到环境变量 |
| **前端 API 地址** | ⚠️ 部分硬编码 | 建议统一管理 |
| **端口配置** | ⚠️ 硬编码 | 建议迁移到环境变量 |

---

## 二、详细排查结果

### 2.1 后端服务 (Backend)

#### ✅ 已正确配置的环境变量

| 变量名 | 文件位置 | 用途 | 状态 |
|-------|---------|------|------|
| `LLM_PROVIDER` | `backend/src/services/llmService.js:8` | LLM 供应商选择 | ✅ 正确 |
| `TONGYI_API_KEY` | `backend/src/services/llmService.js:16` | 通义千问 API Key | ✅ 正确 |
| `DEEPSEEK_API_KEY` | `backend/src/services/llmService.js:22` | DeepSeek API Key | ✅ 正确 |

#### ⚠️ 建议迁移到环境变量的配置

##### 1. LLM API Base URLs（硬编码）

**文件**: `backend/src/services/llmService.js`

```javascript
// 第 17 行
baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1',

// 第 23 行
baseURL: 'https://api.deepseek.com/v1',
```

**问题**:
- API 端点硬编码，切换环境或使用代理时需要修改代码
- 无法灵活适配不同部署环境（开发/测试/生产）

**建议**:
```javascript
baseURL: process.env.TONGYI_BASE_URL || 'https://dashscope.aliyuncs.com/compatible-mode/v1',
baseURL: process.env.DEEPSEEK_BASE_URL || 'https://api.deepseek.com/v1',
```

##### 2. LLM 模型名称（硬编码）

**文件**: `backend/src/services/llmService.js`

```javascript
// 第 41 行
model: 'qwen-plus', // 可替换为 qwen-max 或 qwen-turbo

// 第 48 行
model: 'deepseek-chat',
```

**问题**:
- 模型切换需要修改代码
- 不同环境可能需要使用不同模型（开发用便宜的，生产用效果好的）

**建议**:
```javascript
model: process.env.TONGYI_MODEL || 'qwen-plus',
model: process.env.DEEPSEEK_MODEL || 'deepseek-chat',
```

##### 3. LLM 参数配置（硬编码）

**文件**: `backend/src/services/llmService.js`

```javascript
// 第 43-44 行和 49-50 行
temperature: 0.8,
max_tokens: 1000,
```

**问题**:
- 生成参数固定，无法根据场景调整
- A/B 测试不同参数需要修改代码

**建议**:
```javascript
temperature: parseFloat(process.env.LLM_TEMPERATURE || '0.8'),
max_tokens: parseInt(process.env.LLM_MAX_TOKENS || '1000'),
```

##### 4. 服务器端口（当前在命令行指定）

**文件**: `backend/package.json`

```json
"scripts": {
  "dev": "nodemon src/server.js",
  "start": "node src/server.js"
}
```

**文件**: `backend/src/server.js`（推测）

**建议**: 
- 使用 `process.env.PORT || 3002`
- 在 `.env` 中配置 `PORT=3002`

---

### 2.2 小程序端 (Miniprogram)

#### ⚠️ 硬编码的 API 地址

**文件**: `miniprogram/config/index.js`

```javascript
// 第 8 行 - 开发环境 API 地址有误！
apiBaseUrl: 'http://localhost:3001',  // ❌ 应该是 3002

// 第 13 行 - 生产环境占位符
apiBaseUrl: 'https://your-production-domain.com', // TODO: 部署后替换为实际域名
```

**问题**:
1. ❌ **开发环境端口错误**: 后端运行在 `3002`，这里写的是 `3001`
2. ⚠️ **生产域名未配置**: 占位符需要替换
3. ⚠️ **配置分散**: 不同环境的配置硬编码在代码中

**建议**:
由于小程序无法直接读取 `.env` 文件，建议：
1. 立即修正开发环境端口为 `3002`
2. 使用微信小程序的云开发环境变量功能
3. 或者在构建时通过脚本注入环境变量

**当前方案评估**:
- ✅ 使用 `wx.getAccountInfoSync()` 自动判断环境（develop/trial/release）的设计是正确的
- ⚠️ 但配置值本身仍然硬编码

---

### 2.3 Web 前端 (Web)

#### ⚠️ 硬编码的配置

**文件**: `web/vite.config.js`

```javascript
// 第 8 行
port: 5174,

// 第 11 行
target: 'http://localhost:3002',
```

**问题**:
- 开发端口和代理目标硬编码
- 团队成员可能需要不同端口（端口冲突）
- 无法灵活切换后端地址（本地/远程）

**建议**:
Vite 支持 `.env` 文件，建议使用：

```javascript
// vite.config.js
export default defineConfig({
  server: {
    port: parseInt(process.env.VITE_PORT || '5174'),
    proxy: {
      '/api': {
        target: process.env.VITE_API_PROXY_TARGET || 'http://localhost:3002',
        changeOrigin: true,
        secure: false,
      }
    }
  }
})
```

**`.env.development`**:
```bash
VITE_PORT=5174
VITE_API_PROXY_TARGET=http://localhost:3002
```

---

## 三、建议的 .env 文件结构

### 3.1 Backend `.env` 示例

**文件路径**: `backend/.env`

```bash
# ========== 服务器配置 ==========
PORT=3002
NODE_ENV=development

# ========== LLM 供应商配置 ==========
LLM_PROVIDER=deepseek  # 可选: tongyi, deepseek

# ========== 通义千问配置 ==========
TONGYI_API_KEY=your-tongyi-api-key-here
TONGYI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
TONGYI_MODEL=qwen-plus  # 可选: qwen-max, qwen-turbo

# ========== DeepSeek 配置 ==========
DEEPSEEK_API_KEY=your-deepseek-api-key-here
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
DEEPSEEK_MODEL=deepseek-chat

# ========== LLM 调用参数 ==========
LLM_TEMPERATURE=0.8
LLM_MAX_TOKENS=1000

# ========== 限流配置 ==========
RATE_LIMIT_PER_MINUTE=6

# ========== 缓存配置 ==========
CACHE_TTL=600  # 秒，默认 10 分钟
```

### 3.2 Web `.env.development` 示例

**文件路径**: `web/.env.development`

```bash
# ========== 开发服务器配置 ==========
VITE_PORT=5174

# ========== API 代理配置 ==========
VITE_API_PROXY_TARGET=http://localhost:3002
```

### 3.3 Web `.env.production` 示例

**文件路径**: `web/.env.production`

```bash
# ========== 生产环境 API 配置 ==========
# 生产环境下，前端通常通过 nginx 代理，无需配置
# 或者配置为实际的 API 域名
VITE_API_BASE_URL=https://api.your-domain.com
```

### 3.4 `.env.example` 模板

**文件路径**: `backend/.env.example`

```bash
# ========== 服务器配置 ==========
PORT=3002
NODE_ENV=development

# ========== LLM 供应商配置 ==========
LLM_PROVIDER=tongyi

# ========== 通义千问配置 ==========
TONGYI_API_KEY=sk-xxxxxxxxxxxxxx
TONGYI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
TONGYI_MODEL=qwen-plus

# ========== DeepSeek 配置 ==========
DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxx
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
DEEPSEEK_MODEL=deepseek-chat

# ========== LLM 调用参数 ==========
LLM_TEMPERATURE=0.8
LLM_MAX_TOKENS=1000

# ========== 限流配置 ==========
RATE_LIMIT_PER_MINUTE=6

# ========== 缓存配置 ==========
CACHE_TTL=600
```

---

## 四、需要立即修正的问题

### ❌ 严重问题：小程序开发环境端口错误

**文件**: `miniprogram/config/index.js:8`

```javascript
// 当前（错误）
apiBaseUrl: 'http://localhost:3001',

// 应改为
apiBaseUrl: 'http://localhost:3002',
```

**影响**: 小程序开发环境无法连接后端服务

---

## 五、安全最佳实践

### 5.1 .gitignore 配置

确保 `.gitignore` 包含：

```gitignore
# 环境变量文件
.env
.env.local
.env.*.local

# 但保留示例文件
!.env.example
```

### 5.2 敏感信息检查清单

- [x] API Keys 使用环境变量 ✅
- [x] 没有硬编码密码 ✅
- [x] 没有硬编码 Token ✅
- [ ] API Base URLs 建议迁移 ⚠️
- [ ] 端口配置建议迁移 ⚠️
- [ ] LLM 模型名称建议迁移 ⚠️

### 5.3 环境变量命名规范

遵循以下规范：
- ✅ 使用大写字母和下划线：`TONGYI_API_KEY`
- ✅ 按模块分组：`LLM_`, `CACHE_`, `RATE_LIMIT_`
- ✅ 提供默认值：`process.env.PORT || 3002`
- ✅ 类型转换：`parseInt()`, `parseFloat()`, `Boolean()`

---

## 六、优先级分类

### P0 - 立即修正

1. ❌ **修正小程序开发环境端口**：`3001` → `3002`

### P1 - 建议在下次迭代完成

1. ⚠️ **创建 `.env.example` 模板文件**
2. ⚠️ **迁移 LLM Base URLs 到环境变量**
3. ⚠️ **迁移 LLM 模型名称到环境变量**
4. ⚠️ **配置生产环境 API 域名**（小程序 + Web）

### P2 - 可选优化

1. 迁移 LLM 参数（temperature, max_tokens）到环境变量
2. 迁移缓存 TTL 到环境变量
3. Web 端使用 Vite 环境变量

---

## 七、实施建议

### 步骤 1：立即修正小程序端口

```javascript
// miniprogram/config/index.js
const devConfig = {
  apiBaseUrl: 'http://localhost:3002', // 修正端口
};
```

### 步骤 2：创建 .env.example

在 `backend/` 目录创建 `.env.example`，内容见上文 3.4 节。

### 步骤 3：修改代码支持环境变量

修改 `backend/src/services/llmService.js`：

```javascript
initProvider() {
  if (this.provider === 'tongyi') {
    this.client = new OpenAI({
      apiKey: process.env.TONGYI_API_KEY,
      baseURL: process.env.TONGYI_BASE_URL || 'https://dashscope.aliyuncs.com/compatible-mode/v1',
    });
  } else if (this.provider === 'deepseek') {
    this.client = new OpenAI({
      apiKey: process.env.DEEPSEEK_API_KEY,
      baseURL: process.env.DEEPSEEK_BASE_URL || 'https://api.deepseek.com/v1',
    });
  }
}

async generate({ mode, style, locale, count, audienceAge, intensity }) {
  // ...
  const model = this.provider === 'tongyi' 
    ? (process.env.TONGYI_MODEL || 'qwen-plus')
    : (process.env.DEEPSEEK_MODEL || 'deepseek-chat');
  
  const temperature = parseFloat(process.env.LLM_TEMPERATURE || '0.8');
  const max_tokens = parseInt(process.env.LLM_MAX_TOKENS || '1000');
  
  response = await this.client.chat.completions.create({
    model,
    messages,
    temperature,
    max_tokens,
  });
}
```

### 步骤 4：更新文档

在 `init.sh` 或 README 中说明：
1. 复制 `.env.example` 到 `.env`
2. 填写必要的 API Keys
3. 根据需要调整其他配置

---

## 八、总结

### 当前状态评分：7/10

**优点**:
- ✅ API Keys 已正确使用环境变量
- ✅ 已安装 `dotenv` 依赖
- ✅ 小程序已实现环境判断逻辑

**需要改进**:
- ❌ 小程序开发环境端口配置错误
- ⚠️ 缺少 `.env.example` 模板
- ⚠️ 部分配置硬编码（API URLs、模型名称、端口）
- ⚠️ 生产环境配置未完成

### 建议行动

1. **立即执行**: 修正小程序端口配置
2. **本周完成**: 创建 `.env.example` + 迁移 API URLs
3. **下次迭代**: 完善环境变量支持，配置生产环境

---

**报告时间**: 2025-12-17 16:41  
**排查完成**: ✅  
**发现问题**: 1 个严重问题（P0），4 个建议改进（P1）

